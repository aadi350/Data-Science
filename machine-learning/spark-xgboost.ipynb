{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-1.8.0-openjdk-amd64'\n",
    "os.environ['PYSPARK_PYTHON'] = '/home/aadi/miniconda3/envs/spark_env/bin/python' \n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/home/aadi/miniconda3/envs/spark_env/bin/python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import feature\n",
    "import pyspark \n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class ModelNotTrainedException(Exception):\n",
    "    def __init__(self, message):\n",
    "        self.message = message\n",
    "\n",
    "class SparkXGBClassifier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target:str, keys=[], **sparkxgbparams) -> None:\n",
    "        self.target = target\n",
    "        self.keys = keys\n",
    "        self.sdf = None\n",
    "        self.model = None\n",
    "        self.clf = SparkXGBClassifier(\n",
    "            **sparkxgbparams\n",
    "            label_col=target,\n",
    "            features_col='features',\n",
    "        )\n",
    "\n",
    "    def _vectorise(self, sdf):\n",
    "        self.sdf = sdf\n",
    "        vs = feature.VectorAssembler(\n",
    "            inputCols=sdf.drop(*[*self.keys, self.target]).columns,\n",
    "            outputCol='features', \n",
    "            handleInvalid='keep'\n",
    "        )\n",
    "\n",
    "        return vs.transform(sdf)\n",
    "\n",
    "    def fit(self, sdf):\n",
    "        vec = self._vectorise(sdf)\n",
    "        self.model = self.clf.fit(vec)\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, sdf):\n",
    "        if not self.model:\n",
    "            raise ModelNotTrainedException('fit() must be run before calling predict()')\n",
    "        return self.clf.transform(sdf).select(*[*self.sdf.columns, 'rawPrediction', 'probability'])\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadi/miniconda3/envs/spark_env/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:371: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "from pandas import DataFrame\n",
    "\n",
    "N = 1000\n",
    "df = DataFrame({\n",
    "    'num1': random.normal(100, 10, size=N),\n",
    "    'num2': random.normal(100, 10, size=N),\n",
    "    'num3': random.normal(100, 10, size=N),\n",
    "    'cat1': random.choice([0, 1], size=N),\n",
    "    'cat2': random.choice([0, 1], size=N),\n",
    "    'target': random.choice([0, 1], p=[0.9, 0.1], size=N) \n",
    "})\n",
    "\n",
    "sdf = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+----+----+------+\n",
      "|              num1|              num2|              num3|cat1|cat2|target|\n",
      "+------------------+------------------+------------------+----+----+------+\n",
      "|  98.2435509680153|104.93204127892011|121.68163854911032|   1|   1|     0|\n",
      "| 90.38698745904239|111.62499023848352| 97.42047476171886|   1|   0|     0|\n",
      "|102.06766565063468|105.48408648246144| 95.53154938287331|   1|   1|     0|\n",
      "| 79.99136197520531|102.72658512411729| 85.72984330685046|   0|   0|     0|\n",
      "| 94.52144416926258|106.63120413180721| 92.19556052650287|   0|   0|     0|\n",
      "| 96.75326657976005|100.92777760247088| 86.78045752245558|   1|   0|     0|\n",
      "| 97.89071928358211| 87.28374292509204| 88.98380826949743|   1|   0|     0|\n",
      "|103.84709353154184|143.18551705249897|105.65693954097746|   0|   0|     0|\n",
      "| 96.19520221212967| 83.08510925545953| 96.12402175702199|   1|   1|     0|\n",
      "|107.65187942754865|  87.2800246590321| 93.04929914522802|   0|   1|     0|\n",
      "| 92.11060088382274|  80.7956005618842| 90.51351183338765|   0|   1|     0|\n",
      "| 96.44952368549055|104.40626688418574| 90.88739086295253|   0|   0|     1|\n",
      "| 92.05868437835696|100.78070014853661|105.07443332305837|   1|   0|     0|\n",
      "|  84.6351817747001| 89.94227916927129| 94.22527318664238|   0|   1|     0|\n",
      "|102.56752566509294|100.57049547750287|108.12401454843706|   0|   1|     0|\n",
      "| 77.47538613652355| 95.54264030603191| 96.63544510302717|   1|   1|     0|\n",
      "|  94.9554745845636| 98.55735160346134|111.17661001034749|   0|   1|     0|\n",
      "|120.16110721806544| 77.76475041991182|108.00408475284453|   0|   0|     0|\n",
      "|107.12623986829345|104.24598274755546|106.63433921420739|   1|   0|     0|\n",
      "| 99.70591968161013|106.26045101857851| 100.9687897940401|   1|   1|     0|\n",
      "+------------------+------------------+------------------+----+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import feature\n",
    "\n",
    "vs = feature.VectorAssembler(\n",
    "    inputCols=sdf.drop('target').columns,\n",
    "    outputCol='features', \n",
    "    handleInvalid='keep'\n",
    ")\n",
    "\n",
    "vec = vs.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:22:08] task 3 got new rank 0                                    (0 + 4) / 4]\n",
      "[08:22:08] task 2 got new rank 1\n",
      "[08:22:08] task 1 got new rank 2\n",
      "[08:22:08] task 0 got new rank 3\n",
      "/home/aadi/miniconda3/envs/spark_env/lib/python3.8/site-packages/xgboost/sklearn.py:782: UserWarning: Loading a native XGBoost model with Scikit-Learn interface.\n",
      "  warnings.warn(\"Loading a native XGBoost model with Scikit-Learn interface.\")\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from xgboost.spark import SparkXGBClassifier\n",
    "\n",
    "param = {\n",
    "  'max_depth': 8, \n",
    "  'learning_rate': 0.3, \n",
    "  'tree_method': 'hist', \n",
    "  'num_parallel_tree': 8, \n",
    "  'eval_metric': 'auc',\n",
    "}\n",
    "\n",
    "clf = SparkXGBClassifier(\n",
    "    **param,\n",
    "    features_col='features',\n",
    "    label_col='target',\n",
    "    num_workers=4,\n",
    "    use_gpu=False,\n",
    "    verbose=3\n",
    ")\n",
    "clf = clf.fit(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+----+----+------+--------------------+--------------------+----------+--------------------+\n",
      "|              num1|              num2|              num3|cat1|cat2|target|            features|       rawPrediction|prediction|         probability|\n",
      "+------------------+------------------+------------------+----+----+------+--------------------+--------------------+----------+--------------------+\n",
      "|  98.2435509680153|104.93204127892011|121.68163854911032|   1|   1|     0|[98.2435509680153...|[4.24246597290039...|       0.0|[0.98583149909973...|\n",
      "| 90.38698745904239|111.62499023848352| 97.42047476171886|   1|   0|     0|[90.3869874590423...|[3.14202928543090...|       0.0|[0.95859348773956...|\n",
      "|102.06766565063468|105.48408648246144| 95.53154938287331|   1|   1|     0|[102.067665650634...|[5.42074489593505...|       0.0|[0.99559563398361...|\n",
      "| 79.99136197520531|102.72658512411729| 85.72984330685046|   0|   0|     0|[79.9913619752053...|[4.05952072143554...|       0.0|[0.98303544521331...|\n",
      "| 94.52144416926258|106.63120413180721| 92.19556052650287|   0|   0|     0|[94.5214441692625...|[2.98702716827392...|       0.0|[0.95198458433151...|\n",
      "| 96.75326657976005|100.92777760247088| 86.78045752245558|   1|   0|     0|[96.7532665797600...|[3.28359460830688...|       0.0|[0.96386170387268...|\n",
      "| 97.89071928358211| 87.28374292509204| 88.98380826949743|   1|   0|     0|[97.8907192835821...|[2.82826495170593...|       0.0|[0.94418424367904...|\n",
      "|103.84709353154184|143.18551705249897|105.65693954097746|   0|   0|     0|[103.847093531541...|[3.34398961067199...|       0.0|[0.96590745449066...|\n",
      "| 96.19520221212967| 83.08510925545953| 96.12402175702199|   1|   1|     0|[96.1952022121296...|[3.98440384864807...|       0.0|[0.98173624277114...|\n",
      "|107.65187942754865|  87.2800246590321| 93.04929914522802|   0|   1|     0|[107.651879427548...|[4.25166034698486...|       0.0|[0.98595935106277...|\n",
      "| 92.11060088382274|  80.7956005618842| 90.51351183338765|   0|   1|     0|[92.1106008838227...|[3.92881846427917...|       0.0|[0.98071241378784...|\n",
      "| 96.44952368549055|104.40626688418574| 90.88739086295253|   0|   0|     1|[96.4495236854905...|[-0.5818654298782...|       1.0|[0.35850346088409...|\n",
      "| 92.05868437835696|100.78070014853661|105.07443332305837|   1|   0|     0|[92.0586843783569...|[3.40142655372619...|       0.0|[0.96774911880493...|\n",
      "|  84.6351817747001| 89.94227916927129| 94.22527318664238|   0|   1|     0|[84.6351817747001...|[4.98005533218383...|       0.0|[0.99317324161529...|\n",
      "|102.56752566509294|100.57049547750287|108.12401454843706|   0|   1|     0|[102.567525665092...|[4.55137681961059...|       0.0|[0.98955750465393...|\n",
      "| 77.47538613652355| 95.54264030603191| 96.63544510302717|   1|   1|     0|[77.4753861365235...|[2.23381876945495...|       0.0|[0.90324562788009...|\n",
      "|  94.9554745845636| 98.55735160346134|111.17661001034749|   0|   1|     0|[94.9554745845636...|[3.54626870155334...|       0.0|[0.97197598218917...|\n",
      "|120.16110721806544| 77.76475041991182|108.00408475284453|   0|   0|     0|[120.161107218065...|[5.90958499908447...|       0.0|[0.99729400873184...|\n",
      "|107.12623986829345|104.24598274755546|106.63433921420739|   1|   0|     0|[107.126239868293...|[3.81415534019470...|       0.0|[0.97841966152191...|\n",
      "| 99.70591968161013|106.26045101857851| 100.9687897940401|   1|   1|     0|[99.7059196816101...|[5.11811733245849...|       0.0|[0.99404835700988...|\n",
      "+------------------+------------------+------------------+----+----+------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf.transform(vec).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 (default, Nov 24 2022, 15:19:38) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bac5f9a12ce42e3ce4a716d69b8738cd831a51d5f24bd9d0d377d51220bf4645"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
