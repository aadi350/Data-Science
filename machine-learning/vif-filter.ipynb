{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-1.8.0-openjdk-amd64'\n",
    "os.environ['PYSPARK_PYTHON'] = '/home/aadi/miniconda3/envs/pyspark_env/bin/python' \n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/home/aadi/miniconda3/envs/pyspark_env/bin/python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/23 14:17:58 WARN Utils: Your hostname, debian resolves to a loopback address: 127.0.1.1; using 192.168.100.213 instead (on interface wlp5s0)\n",
      "22/12/23 14:17:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/23 14:17:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkSession.Builder().appName('vif').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+----+----+----+------+\n",
      "|              num1|num2|num3|num4|num5|target|\n",
      "+------------------+----+----+----+----+------+\n",
      "| 984.8872605711517|   7|  21|  -8|  -7|     0|\n",
      "|1099.2159034072686|  -4| -12|   6|  -9|     0|\n",
      "|1015.1058028043047|  -3|  -9|   4|  -4|     0|\n",
      "| 985.6084462370345| -10| -30|  -9| -10|     0|\n",
      "|1100.3370751658183|  -9| -27|  -6| -10|     0|\n",
      "| 1063.782948966551| -10| -30|   6|   9|     0|\n",
      "|1140.6366426432483| -10| -30|  -6|   3|     0|\n",
      "|1106.4655584201712|   7|  21|  -1|  -3|     0|\n",
      "|1109.0426584457339|   2|   6|  -1|  -4|     0|\n",
      "|1067.7017606269155|  -5| -15|   8|  -3|     0|\n",
      "|1065.7883926650575|   1|   3|   0|   2|     0|\n",
      "|1141.1533747176907|   2|   6|   7|  -3|     0|\n",
      "|1054.1722186621575|  -9| -27|  -3|   3|     0|\n",
      "|1052.4024936957942|  -3|  -9|   6|  -6|     0|\n",
      "| 966.2962217837946| -10| -30|  -5|   9|     0|\n",
      "| 980.4324534504395|   5|  15|  -4|  -8|     0|\n",
      "|1043.0995064195083|   8|  24|  -5|   2|     0|\n",
      "| 933.0004552758113|  -8| -24|   9|  -5|     0|\n",
      "| 1021.390077155877|  -5| -15| -10|  -5|     0|\n",
      "| 994.2760883571852|  -4| -12|  -4|   4|     0|\n",
      "+------------------+----+----+----+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aadi/miniconda3/envs/pyspark_env/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/home/aadi/miniconda3/envs/pyspark_env/lib/python3.8/site-packages/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "N = 5000\n",
    "data = pd.DataFrame({\n",
    "    'num1': np.random.normal(1000, 100, size=N), \n",
    "    'num2': np.random.randint(low=-10, high=10, size=N),\n",
    "    'num3': np.random.randint(low=-10, high=10, size=N),\n",
    "    'num4': np.random.randint(low=-10, high=10, size=N),\n",
    "    'num5': np.random.randint(low=-10, high=10, size=N),\n",
    "    'target': np.random.choice([0, 1],p=[0.9, 0.1],  size=N)\n",
    "})\n",
    "\n",
    "data = data.assign(num3=data.num2 * 3)\n",
    "\n",
    "dd = sc.createDataFrame(data)\n",
    "dd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import Row\n",
    "\n",
    "# Importing required libraries for VIF Calculation\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_threshold = 5 #Threshold for VIF\n",
    "\n",
    "class VifFilter:\n",
    "  def __init__(self,\n",
    "    label_column,\n",
    "    exclude_cols=None,\n",
    "    vif_threshold=5,\n",
    "    estimator=LogisticRegression,\n",
    "    evaluator=BinaryClassificationEvaluator\n",
    "  ):\n",
    "\n",
    "    self.label_column = label_column\n",
    "    self.exclude_cols = exclude_cols\n",
    "    self.vif_threshold = vif_threshold\n",
    "    self.estimator = estimator\n",
    "    self.evaluator = evaluator\n",
    "\n",
    "  def _reorder_label(self, data):\n",
    "    '''Ensures label is LAST column'''\n",
    "    columns = data.columns\n",
    "    columns.remove(self.label_column)\n",
    "    columns.append(self.label_column)\n",
    "    return data.select(*[columns])\n",
    "\n",
    "\n",
    "  def calc_vif(self, data, xvar_names, vif_max, colnum_max):\n",
    "    print(f'Number columns at this level: {len(data.columns)}')\n",
    "    vif_max = self.vif_threshold\n",
    "    for i in range(2, len(xvar_names)):\n",
    "      train_table = data.rdd.map(lambda x: [Vectors.dense(x[2:i]+x[i+1:]), x[i]]).toDF(['features', 'label'])\n",
    "      lr = self.estimator(featuresCol='features', labelCol='label')\n",
    "      lr_model = lr.fit(train_table)\n",
    "      predictions = lr_model.transform(train_table)\n",
    "      evaluator = self.evaluator(predictionCol='prediction', labelCol='label')\n",
    "      r_sq = evaluator.evaluate(predictions, {evaluator.metricName: 'r2'})\n",
    "      vif = 1/(1-r_sq)\n",
    "      if vif_max < vif:\n",
    "        vif_max = vif\n",
    "        colnum_max = i\n",
    "\n",
    "      return vif_max, colnum_max\n",
    "\n",
    "  def remove_collinear(self, data):\n",
    "\n",
    "    data = self._reorder_label(data)\n",
    "\n",
    "    xvar_names = data.columns\n",
    "    colnum_max = len(xvar_names)\n",
    "    vif_max = self.vif_threshold + 1\n",
    "\n",
    "    while vif_max > 5:\n",
    "      vif_max, colnum_max = self.calc_vif(data, xvar_names, vif_max, colnum_max)\n",
    "      if vif_max > 5:\n",
    "        data = data.drop(data[colnum_max])\n",
    "        xvar_names = data.columns\n",
    "    else:\n",
    "      return data\n",
    "\n",
    "def vif_cal_iter(inputdata,vif_threshold):\n",
    "  xvar_names = inputdata.columns\n",
    "  global vif_max\n",
    "  global colnum_max\n",
    "  colnum_max = 10000 # Initialising with a fake value\n",
    "  vif_max = vif_threshold + 1\n",
    "  def vif_cal(inputdata, xvar_names, vif_max, colnum_max, vif_threshold):\n",
    "    print(\"Dimension of table at this level\")\n",
    "    print(\"================================\")\n",
    "    print(inputdata.count(), len(inputdata.columns))\n",
    "    print(\"List of X Variables\")\n",
    "    print(\"===================\")\n",
    "    print(xvar_names)\n",
    "    vif_max = vif_threshold\n",
    "    for i in range(2,len(xvar_names)):\n",
    "      train_t = inputdata.rdd.map(lambda x: [Vectors.dense(x[2:i]+x[i+1:]), x[i]]).toDF(['features', 'label'])\n",
    "      lr = LinearRegression(featuresCol = 'features', labelCol = 'label')\n",
    "      lr_model = lr.fit(train_t)\n",
    "      predictions = lr_model.transform(train_t)\n",
    "      evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='label')\n",
    "      r_sq=evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "      vif=1/(1-r_sq)\n",
    "      if vif_max < vif:\n",
    "        vif_max = vif\n",
    "        colnum_max = i\n",
    "    return vif_max, colnum_max\n",
    "  while vif_max > 5:\n",
    "    vif_max, colnum_max = vif_cal(inputdata, xvar_names, vif_max, colnum_max, vif_threshold)\n",
    "    if vif_max > vif_threshold:\n",
    "        print(\"Start of If Block\")\n",
    "        inputdata = inputdata.drop(inputdata[colnum_max])\n",
    "        xvar_names = inputdata.columns\n",
    "        print(\"Dimension of table after this iteration\")\n",
    "        print(\"=======================================\")\n",
    "        print(inputdata.count(), len(inputdata.columns))\n",
    "        print(\"List of X Variables remaining\")\n",
    "        print(\"=============================\")\n",
    "        print(xvar_names)\n",
    "  else:\n",
    "    return inputdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num1', 'num2', 'num3', 'num4', 'num5']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dd\n",
    "col_names = data.columns\n",
    "col_names.remove('target') # works inplace\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop actual target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(num1=936.4082310320396, num2=5, num3=15, num4=2, num5=-6, target=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VifFilter: pass\n",
    "\n",
    "def calc_vif(self, data, target_name=None):\n",
    "    if target_name and target_name in data.columns:\n",
    "        data = data.drop(target_name)\n",
    "\n",
    "    vifs = pd.Series(name='vif', dtype='float64')\n",
    "    col_names = list(data.columns)\n",
    "    for idx, colname in enumerate(col_names):\n",
    "        train_table = data.rdd.map(lambda x: [Vectors.dense(x[:idx]+x[idx+1:]), x[idx]]).toDF(['features', 'label'])\n",
    "        lr = LinearRegression(featuresCol='features', labelCol='label') \n",
    "        lr_model = lr.fit(train_table)\n",
    "        predictions = lr_model.transform(train_table)\n",
    "        eval = RegressionEvaluator(predictionCol='prediction', labelCol='label') \n",
    "        r_sq = eval.evaluate(predictions, {eval.metricName: 'r2'})\n",
    "\n",
    "        try:\n",
    "            vif = 1/(1-r_sq)\n",
    "        except ZeroDivisionError as z:\n",
    "            # this means perfect correlation, set to high number\n",
    "            vif = float('Inf')\n",
    "        vifs[colname] = vif\n",
    "\n",
    "    return vifs.sort_values()\n",
    "VifFilter.calc_vif = calc_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/23 15:54:32 WARN Instrumentation: [90cfa142] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 15:54:32 WARN Instrumentation: [90cfa142] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "22/12/23 15:54:33 WARN Instrumentation: [9d8aea5d] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 15:54:34 WARN Instrumentation: [9e3fc421] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 15:54:34 WARN Instrumentation: [392af55b] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 15:54:35 WARN Instrumentation: [392af55b] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "22/12/23 15:54:35 WARN Instrumentation: [b6fbc8ee] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 15:54:35 WARN Instrumentation: [b6fbc8ee] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "num4    1.000641\n",
       "num1    1.000703\n",
       "num5    1.000932\n",
       "num2         inf\n",
       "num3         inf\n",
       "Name: vif, dtype: float64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf = VifFilter()\n",
    "vf.calc_vif(dd, target_name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import ChiSquareTest\n",
    "\n",
    "def calc_target_corr(self, data, target_name):\n",
    "    if target_name not in data.columns:\n",
    "        raise AttributeError(f'{target_name} not found in data')\n",
    "\n",
    "    # reorganize column order\n",
    "    col_names = list(data.columns)\n",
    "    col_names.remove(target_name)\n",
    "    col_names.append(target_name)\n",
    "\n",
    "    data = data.select(*[col_names])\n",
    "    train_table = data.rdd.map(lambda x: [Vectors.dense(x[:-1]), x[-1]]).toDF(['features', 'label'])\n",
    "    chi2res = ChiSquareTest.test(train_table, 'features', 'label', flatten=True).toPandas()\n",
    "    chi2res = chi2res.assign(featureName=col_names[:-1])[['featureName', 'pValue', 'statistic']]\n",
    "\n",
    "    return chi2res.set_index('featureName')\n",
    "\n",
    "\n",
    "VifFilter.calc_chi2_corr = calc_target_corr\n",
    "vf = VifFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/23 15:55:39 WARN Instrumentation: [18fa28a7] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 15:55:39 WARN Instrumentation: [18fa28a7] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "22/12/23 15:55:39 WARN Instrumentation: [63fb0fb4] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 15:55:40 WARN Instrumentation: [cdf47fea] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 15:55:41 WARN Instrumentation: [37d86159] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 15:55:41 WARN Instrumentation: [37d86159] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "22/12/23 15:55:42 WARN Instrumentation: [5a46919b] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 15:55:42 WARN Instrumentation: [5a46919b] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n"
     ]
    }
   ],
   "source": [
    "chi2_corr= vf.calc_chi2_corr(dd, target_name='target')\n",
    "vifs = vf.calc_vif(data, target_name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+----+----+----+------+\n",
      "|              num1|num2|num3|num4|num5|target|\n",
      "+------------------+----+----+----+----+------+\n",
      "| 983.4712302534647|   1|   3|   2|   1|     0|\n",
      "| 979.0702829763949|   5|  15|   2|   4|     0|\n",
      "|1055.8307118259404| -10| -30|  -9|  -1|     0|\n",
      "| 1037.987618082322|  -8| -24|  -9|  -8|     1|\n",
      "|1169.7448679455354|  -5| -15|  -3|   9|     0|\n",
      "+------------------+----+----+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.data = dd \n",
    "vf.vif_threshold = 5\n",
    "vf.target_name = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self = vf\n",
    "self.vif_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/23 16:02:37 WARN Instrumentation: [6568e499] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 16:02:38 WARN Instrumentation: [6568e499] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "22/12/23 16:02:38 WARN Instrumentation: [887d8047] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 16:02:39 WARN Instrumentation: [430a21e0] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 16:02:40 WARN Instrumentation: [3b60b1c4] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 16:02:40 WARN Instrumentation: [3b60b1c4] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "22/12/23 16:02:40 WARN Instrumentation: [d188a241] regParam is zero, which might cause numerical instability and overfitting.\n",
      "22/12/23 16:02:41 WARN Instrumentation: [d188a241] Cholesky solver failed due to singular covariance matrix. Retrying with Quasi-Newton solver.\n",
      "['num1', 'num2', 'num3', 'num4', 'num5', 'target']\n"
     ]
    }
   ],
   "source": [
    "max_vif = float('Inf')\n",
    "col_names = self.data.columns\n",
    "chi2_corr = self.calc_chi2_corr(self.data, self.target_name)\n",
    "\n",
    "\n",
    "data = dd #self.data\n",
    "\n",
    "while max_vif > self.vif_threshold:\n",
    "    vifs = self.calc_vif(data, target_name=self.target_name)\n",
    "    vif_chi2 = (\n",
    "        vifs.to_frame()\n",
    "        .merge(chi2_corr, left_index=True, right_index=True)\n",
    "        .sort_values(['vif', 'statistic'], ascending=True)\n",
    "    )\n",
    "\n",
    "    # drop highest column value\n",
    "    col_names_reduced = vif_chi2.index[:-1]\n",
    "    print(col_names)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VIFFilter:\n",
    "    def __init__(self, \n",
    "        vif_threshold,\n",
    "        target_name,\n",
    "    ) -> None:\n",
    "        self.vif_threshold = vif_threshold\n",
    "        self.target_name = target_name\n",
    "\n",
    "\n",
    "    def remove_mulitocollinear(self, data, max_iter=None):\n",
    "        max_vif = float('Inf')\n",
    "        col_names = data.columns\n",
    "        chi2_corr = self.calc_target_corr(data, self.target_name)\n",
    "        it = 0\n",
    "        while max_vif > self.vif_threshold:\n",
    "            if max_iter and it > max_iter:\n",
    "                break\n",
    "            vifs = self.calc_vif(data, target_name=self.target_name)\n",
    "            vif_chi2 = (\n",
    "                vifs.to_frame()\n",
    "                    .merge(chi2_corr, left_index=True, right_index=True)\n",
    "                    .sort_values(['vif', 'statistic'], ascending=True)\n",
    "            )\n",
    "\n",
    "            col_names_reduced = vif_chi2.index[:-1]\n",
    "            print(col_names_reduced)\n",
    "            data = data.select(*col_names_reduced)\n",
    "\n",
    "            max_vif = vifs.max()\n",
    "\n",
    "        return data\n",
    "\n",
    "    \n",
    "    def calc_target_corr(self, data, target_name):\n",
    "        if target_name not in data.columns:\n",
    "            raise AttributeError(f'{target_name} not found in data')\n",
    "\n",
    "        # reorganize column order\n",
    "        col_names = list(data.columns)\n",
    "        col_names.remove(target_name)\n",
    "        col_names.append(target_name)\n",
    "\n",
    "        data = data.select(*[col_names])\n",
    "        train_table = data.rdd.map(lambda x: [Vectors.dense(x[:-1]), x[-1]]).toDF(['features', 'label'])\n",
    "        chi2res = ChiSquareTest.test(train_table, 'features', 'label', flatten=True).toPandas()\n",
    "        chi2res = chi2res.assign(featureName=col_names[:-1])[['featureName', 'pValue', 'statistic']]\n",
    "\n",
    "        return chi2res.set_index('featureName')\n",
    "\n",
    "    def calc_vif(self, data, target_name=None):\n",
    "        if target_name and target_name in data.columns:\n",
    "            data = data.drop(target_name)\n",
    "\n",
    "        vifs = pd.Series(name='vif', dtype='float64')\n",
    "        col_names = list(data.columns)\n",
    "        for idx, colname in enumerate(col_names):\n",
    "            train_table = data.rdd.map(lambda x: [Vectors.dense(x[:idx]+x[idx+1:]), x[idx]]).toDF(['features', 'label'])\n",
    "            lr = LinearRegression(featuresCol='features', labelCol='label', regParam=0.5) \n",
    "            lr_model = lr.fit(train_table)\n",
    "            predictions = lr_model.transform(train_table)\n",
    "            eval = RegressionEvaluator(predictionCol='prediction', labelCol='label') \n",
    "            r_sq = eval.evaluate(predictions, {eval.metricName: 'r2'})\n",
    "\n",
    "            try:\n",
    "                vif = 1/(1-r_sq)\n",
    "            except ZeroDivisionError as z:\n",
    "                # this means perfect correlation, set to high number\n",
    "                vif = float('Inf')\n",
    "            vifs[colname] = vif\n",
    "\n",
    "        return vifs.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = VIFFilter(\n",
    "    5, \n",
    "    'target'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['num4', 'num1', 'num5', 'num2'], dtype='object')\n",
      "Index(['num2', 'num4', 'num1'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[num2: bigint, num4: bigint, num1: double]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vf.remove_mulitocollinear(dd, max_iter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vifs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:49:35) \n[GCC 10.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c381e67c3557bc3722f390a24d9b4637bf98cf80995ba2adfe7961e7381da7d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
