{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1QLUxbyECZa"
      },
      "source": [
        "This entire post is dedicated to coming to terms with `tensorflow`'s metrics, and the varying input formats associated with it. It is a direct result of me not using the correct version of a metric and leaving a model to train for 4 days (only realising afterwards that I should have used the non-sparse version of Accuracy). \n",
        "\n",
        "This is not meant to expose the underpinnings and statistical wizardry of the intentions of these metrics (information theory, physics, etc), but is rather meant to be my notes on how to correctly use these metrics in deep-learning applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD2nZ8RwyRSg"
      },
      "source": [
        "# Accuracy-Derived"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmvF3ecNCaCA"
      },
      "source": [
        "## Accuracy\n",
        "\n",
        "Probably not the one you should use, this expects a list, where each item is a prediction label The only place I've seen it used is in the [CropNet example](https://www.tensorflow.org/hub/tutorials/cropnet_cassava), where individual examples were evaluated separately. Most architectures for classification typically output a vector of class probabilities, as opposed to a hard prediction, so this might be useful after-the-fact OR if you threshold the vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3jPZYf_CWWL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqwp_WD5CdDZ",
        "outputId": "39ceaf1b-9bbb-4d4f-99ed-38aefcd83e7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.75>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# binary example\n",
        "y_actual = [1, 0, 0, 1]\n",
        "y_pred = [1, 1, 0, 1] # we expect 0.75% accuracy\n",
        "\n",
        "m = metrics.Accuracy()\n",
        "m(y_actual, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TbKHCMgC1SG",
        "outputId": "2c8a5319-54d2-403e-d87d-6834b2e063af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.75>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# multinomial example\n",
        "y_actual = [1, 2, 3, 4]\n",
        "y_pred = [1, 2, 2, 4] # we expect 0.75% accuracy\n",
        "\n",
        "m = metrics.Accuracy()\n",
        "m(y_actual, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWzao1VWA1hi",
        "outputId": "869aee4d-7fab-4ec7-bbd2-19e32adf9bfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# OHE? Apparently not\n",
        "y_actual = [\n",
        "    [0, 1, 0],\n",
        "    [1, 0, 0]\n",
        "]\n",
        "\n",
        "y_pred = [\n",
        "    [0.2, 0.5, 0.3],\n",
        "    [0.2, 0.5, 0.3],\n",
        "]\n",
        "\n",
        "m = metrics.Accuracy()\n",
        "m(y_actual, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBKS5w8HDYSj"
      },
      "source": [
        "## Binary Accuracy\n",
        "\n",
        "This seems to be controlled via a threshold parameter, and is a specific version of the above. This might be useful if (e.g.) your network has a single output cell `Dense(1)`, which represents a positive/negative class.\n",
        "\n",
        "This is a simple:\n",
        "$$\n",
        "\\frac{\\text{Number True Predictions}}{\\text{Number Predictions}}\n",
        "$$ \n",
        "(exactly the same as Accuracy above, except each entry is expected to be some probability of class) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH1nXbcdCmXN",
        "outputId": "2686a3b1-d997-4fba-f856-c7feb55afba4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.75>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m = tf.keras.metrics.BinaryAccuracy(threshold=0.5)\n",
        "m([1, 0, 0, 1], [0.501, 0, 1, 1]) # expect 0.75 when default threshold used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDhXb7izyIWQ"
      },
      "source": [
        "## Categorical Accuracy\n",
        "This is one of my most-used accuracy measures. It calcualtes how often predictions match one-hot-labels. `y_true` and `y_pred` are both one-hot encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUez953yyJa8",
        "outputId": "eb690fb6-c5d0-408e-ef36-1e84391b4e2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = [\n",
        "    [1, 0, 0],\n",
        "    [0, 0, 1],\n",
        "]\n",
        "y_pred = [\n",
        "    [0.6, 0.15, 0.25],\n",
        "    [0.5, 0.3, 0.2], # expect 50% accuracy\n",
        "]\n",
        "\n",
        "m = metrics.CategoricalAccuracy()\n",
        "m(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipS4PWUdyWWd"
      },
      "source": [
        "## SparseCategorical Accuracy\n",
        "\n",
        "This expects a vector of class probabilities as `y_pred` and a list of actual class-labels as `y_true`. It is taken as the ratio of the correct predictions (argmax of the vector) over the net number of predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ledwc6NlyrnO",
        "outputId": "e7261793-e711-4479-a951-9945ee1fd8d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = [0, 2] # exactly the same as prior, now just as actual labels\n",
        "\n",
        "m = metrics.SparseCategoricalAccuracy()\n",
        "m(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJ5dtUIszAS_"
      },
      "source": [
        "# Crossentropy-Type\n",
        "\n",
        "As opposed to raw true-vs-false predictions, # TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VdDpMk4EI6x"
      },
      "source": [
        "## Binary Crossentropy\n",
        "\n",
        "If `from_logits` is true, the output is not assumed to be bounded between 0 and 1. (The negative sign is to counteract the fact that log of a number less than 1 is negative)\n",
        "\n",
        "$$\n",
        "\\frac{1}{N}\\sum_{i=1}^N - \\left[y_i \\log(p_i) + (1-y_i)\\log(1-p_i) \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dt_9HP8DSr6",
        "outputId": "51c032a5-6c2d-4794-b4ef-df37befb3ceb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.1642519>"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = [0, 1] # shape is (batch_size, d0, .., dN)\n",
        "y_pred = [0.2, 0.9]\n",
        "m = metrics.BinaryCrossentropy() \n",
        "m(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agnERc4sHgGT"
      },
      "source": [
        "Doing this manually"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CkyHQbZEaEw",
        "outputId": "6c989ffc-4662-41d3-b2c1-bc300b3de193"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.164252033486018"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# manually, N=1 so I ignore that\n",
        "log_loss = 0\n",
        "for y_i, p_i in zip(y_true, y_pred):\n",
        "    log_loss += -(y_i * np.log(p_i) + (1-y_i)*np.log(1-p_i))\n",
        "\n",
        "# so it makes sense, same as above!\n",
        "log_loss /= 2 \n",
        "\n",
        "log_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTpfu6SyHnpe"
      },
      "source": [
        "\n",
        "## Categorical Crossentropy\n",
        "\n",
        "Essentially binary cross-entropy with an added dimension:\n",
        "\n",
        "$$\n",
        "-\\frac{1}{N}\\sum_{i=1}^N \\sum_{j=1}^M  y_{ij} \\log(p_{ij}) \n",
        "$$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6q3HfZgHkao",
        "outputId": "80962db1-53af-4c8b-d544-bf5861aa0634"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.22314353>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = [[0, 0, 1]] # here, our sample belongs to class 2 (index of position is 2)\n",
        "y_pred = [[0.1, 0.1, 0.8]] # our predicted implies class 2 has the highest probability\n",
        "m = metrics.CategoricalCrossentropy()\n",
        "\n",
        "m(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CCrMyoVHYBw",
        "outputId": "31912aff-2804-4eec-9eb3-59e6aedebd28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2231435513142097"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N = 1\n",
        "M = 3\n",
        "log_loss = 0\n",
        "for i in range(N):\n",
        "    for j in range(M):\n",
        "        log_loss -= y_true[i][j]*np.log(y_pred[i][j])\n",
        "            \n",
        "\n",
        "log_loss /= N\n",
        "log_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0oKfs6ezIy7"
      },
      "source": [
        "## Sparse Categorical Crossentropy\n",
        "\n",
        "Exactly the same as above, except accepts `y_true` as single labels, instead of vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVE5YAVSzaPm",
        "outputId": "d524f426-c10a-4514-fb21-fda3e19d17dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.22314355>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = [2]\n",
        "m = metrics.SparseCategoricalCrossentropy()\n",
        "\n",
        "m(y_true, y_pred) # the answer should be EXACTLY the same as above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-qSr2RPzovY"
      },
      "source": [
        "# Checkpoint - What does \"sparse\" mean?\n",
        "So the difference between accuracy/crossentropy and their respective *sparse* versions are the format of the labels. The sparse versions expect that the labels are defined as-is (class 2 implies the label is [2]), whilst the non-sparse versions expect one-hot encoded labels (so the same class 2 looks like [0, 0, 1, 0... N] if we have N classes)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S45qWpr1z-IA"
      },
      "source": [
        "# Other Common Metrics\n",
        "## Mean Absolute Error\n",
        "\n",
        "This is the typical difference between predicted and actual scaled by the number of samples (also taken as the absolute sum of errors)\n",
        "\n",
        "$$\n",
        "\\frac{\\sum_{i=1}^{N}|\\hat{y}-y|}{N}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBj-h-OKzna2",
        "outputId": "ef96aae0-6277-4005-d035-c4a3ec8e2556"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.33333334>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = [1, 1, 2]\n",
        "y_pred = [1, 2, 2] # this expects 0.33 error\n",
        "m = metrics.MeanAbsoluteError()\n",
        "m(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFjfDOWo0whz",
        "outputId": "93f9c963-caa5-4d16-866d-575a615392b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.8333333>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# does it also work with OHE?\n",
        "y_pred = [\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 1],\n",
        "    [0, 0, 1]\n",
        "]\n",
        "m(y_true, y_pred) # apprently not..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQdJNtaQ0_Js",
        "outputId": "d19bc498-dc1b-4a36-8b8f-2c0091349c9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5714286>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# if we define y_true as OHE\n",
        "y_true = [\n",
        "    [0, 1, 0],\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 1],\n",
        "]\n",
        "m(y_true, y_pred) # also no"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC8bkJAf1If0"
      },
      "source": [
        "## Mean Absolute Percentage Error\n",
        "\n",
        "This appears to not only consider how many predictions are wrong, but appears to be scaled by the label (following the usual MAPE formula)\n",
        "\n",
        "$$\n",
        "\\frac{100}{N}\\sum_{i=1}^N \\left|\\frac{y-\\hat{y}}{y} \\right|\n",
        "$$\n",
        "\n",
        "where $y$ is the actual value, and $\\hat{y}$ is the forecast value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsclMQqB1LpY",
        "outputId": "562c911c-78b8-4a9a-beb3-4409cb30f106"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.333334>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = [1, 2, 4]\n",
        "y_pred = [1, 2, 3]\n",
        "\n",
        "m = metrics.MeanAbsolutePercentageError()\n",
        "m(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqHpa7Za1m87",
        "outputId": "88e1b18e-4aa8-4821-8bf2-49560d80a3d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=16.666668>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = [1, 2, 4]\n",
        "y_pred = [1, 2, 2]\n",
        "\n",
        "m = metrics.MeanAbsolutePercentageError()\n",
        "m(y_true, y_pred) # although the same class is wrong, the percentage is different"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM78TDIb2NVz",
        "outputId": "548458e5-2a9b-438d-9cc7-3598042b6266"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16.666666666666668"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# doing it in numpy\n",
        "error = 0\n",
        "N = 3\n",
        "for true, pred in zip(y_true, y_pred):\n",
        "    error += np.abs((true-pred)/true)\n",
        "\n",
        "error *= (100/N)\n",
        "\n",
        "error # seems to line up with the above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK_BhLng1vGy",
        "outputId": "8202f9d1-bed9-427c-82b9-794029708aa4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=8.333334>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# one-hot-encoding?\n",
        "y_true = [[0, 1, 0]]\n",
        "y_pred = [[0, 1, 0]]\n",
        "\n",
        "m(y_true, y_pred) # guess not, because this error is supposed to be zero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1uhMpug2-Ea"
      },
      "source": [
        "## Mean Squared Error\n",
        "\n",
        "This is given as the sum of errors squared:\n",
        "\n",
        "$$\n",
        "\\frac{1}{N}\\sum_{i=1}^N\\left(y_i-\\hat{y}_i\\right)^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCXgxjM038YC",
        "outputId": "6f8da1d3-0b18-40d1-b608-92ec06b9a45b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.33333334>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = [1, 2, 4]\n",
        "y_pred = [1, 2, 3]\n",
        "\n",
        "m = metrics.MeanSquaredError()\n",
        "\n",
        "m(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVRuTN_d4GIZ",
        "outputId": "1aaa3aeb-cce1-4e85-9da3-290c94c3a3a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N = 3\n",
        "error = 0\n",
        "for true, pred in zip(y_true, y_pred):\n",
        "    error += np.power(true-pred, 2)\n",
        "\n",
        "error /= N\n",
        "\n",
        "error # seems about right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuJE5GiN4Yq3",
        "outputId": "8880945b-a84e-43a5-a557-63e6fe176402"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.18333334>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# OHE?\n",
        "y_true = [\n",
        "    [0, 1, 0, 0, 0],\n",
        "    [0, 0, 1, 0, 0],\n",
        "    [0, 0, 0, 0, 1],\n",
        "]\n",
        "\n",
        "y_pred = [\n",
        "    [0, 1, 0, 0, 0],\n",
        "    [0, 0, 1, 0, 0],\n",
        "    [0, 0, 0, 1, 0],\n",
        "]\n",
        "\n",
        "m(y_true, y_pred) # nope, I'm still not even sure how this is calculated...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lZvojRm4p8d",
        "outputId": "f4c9de73-4544-4011-b31e-eabdbf6fd36a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.21666667>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# simpler example\n",
        "y_true = [\n",
        "    [0, 1],\n",
        "]\n",
        "\n",
        "y_pred = [\n",
        "    [1, 0],\n",
        "]\n",
        "\n",
        "m(y_true, y_pred) # THIS SHOULD BE ZERO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg6Qg91z5Jgg"
      },
      "source": [
        "In short: the MSE, MAPE and MAE metrics are not suitable for one-hot-encoded labels/predictions "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz0EPdGh5SCR"
      },
      "source": [
        "## Precision\n",
        "\n",
        "This is taken as:\n",
        "$$\n",
        "\\frac{\\text{Number of true positives}}{\\text{Number of true+false positives}}\n",
        "$$ \n",
        "\n",
        "This implementation only supports binary targets (which makes sense in the context of true-vs-false samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAb8VliJ5gfb",
        "outputId": "3e8cf900-eb02-4bd3-d81e-4d36186004c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# binary example\n",
        "y_true = [0, 1, 0]\n",
        "y_pred = [0, 0.6, 1]\n",
        "\n",
        "m = metrics.Precision()\n",
        "m(y_true, y_pred) # should be 1/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "1n9ejhuB52Jx",
        "outputId": "f3ab77d4-e7d7-48ec-dea8-75504a0bf5f2"
      },
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-7c4421497ddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics/base_metric.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m  \u001b[0;31m# pylint:disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     return distributed_training_utils.call_replica_local_fn(\n\u001b[0;32m--> 201\u001b[0;31m         replica_local_fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/distribute/distributed_training_utils.py\u001b[0m in \u001b[0;36mcall_replica_local_fn\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics/base_metric.py\u001b[0m in \u001b[0;36mreplica_local_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m       \u001b[0mupdate_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# update_op will be None in eager execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics/base_metric.py\u001b[0m in \u001b[0;36mupdate_state_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m         ag_update_state = tf.__internal__.autograph.tf_convert(\n\u001b[1;32m    139\u001b[0m             obj_update_state, control_status)\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mag_update_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/metrics/metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mclass_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mupdate_confusion_matrix_variables\u001b[0;34m(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights, thresholds_distributed_evenly)\u001b[0m\n\u001b[1;32m    607\u001b[0m           \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m           \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m           message='predictions must be <= 1')\n\u001b[0m\u001b[1;32m    610\u001b[0m   ]):\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/check_ops.py\u001b[0m in \u001b[0;36m_binary_assert\u001b[0;34m(sym, opname, op_func, static_func, x, y, data, summarize, message, name)\u001b[0m\n\u001b[1;32m    408\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m           message=('\\n'.join(_pretty_print(d, summarize) for d in data)))\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# not context.executing_eagerly()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 2. 3.]\nFirst 1 elements of y:\n[1.]"
          ]
        }
      ],
      "source": [
        "# multinomial \n",
        "y_true = [1, 2, 3, 3]\n",
        "y_pred = [1, 2, 3, 4]\n",
        "\n",
        "m(y_true, y_pred) # doesn't work here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU3vpbVw5sND",
        "outputId": "8b3e0072-2e59-4c4d-cbc0-89f10b3c3808"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# OHE?\n",
        "y_true = [\n",
        "    [0, 1, 0],\n",
        "    [1, 0, 0]\n",
        "]\n",
        "\n",
        "y_pred = [\n",
        "    [1, 0, 0],\n",
        "    [1, 0, 0],\n",
        "]\n",
        "\n",
        "m(y_true, y_pred) # seems like it's able to handle OHE labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8JIpUx06UJW"
      },
      "source": [
        "## Recall\n",
        "This is taken as:\n",
        "$$\n",
        "\\frac{\\text{Number of true positives}}{\\text{Number of true positives + false negatives}}\n",
        "$$ \n",
        "\n",
        "This implementation only supports binary targets (which makes sense in the context of true-vs-false samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5M-ZsBR70Za",
        "outputId": "e5100696-49bf-4279-96b4-9260dba1ba9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=1.0>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# binary example\n",
        "y_true = [0, 1, 0]\n",
        "y_pred = [0, 1, 1]\n",
        "\n",
        "m = metrics.Recall()\n",
        "m(y_true, y_pred) # should be 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYC4HC-w748_",
        "outputId": "4a87a9f8-6306-4d8d-fffd-87b6ccd3830a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.8888889>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# OHE?\n",
        "y_true = [\n",
        "    [1, 0, 0],\n",
        "    [1, 0, 0]\n",
        "]\n",
        "\n",
        "y_pred = [\n",
        "    [1, 0, 0],\n",
        "    [1, 0, 0],\n",
        "]\n",
        "\n",
        "m(y_true, y_pred) # seems like it's not able to handle OHE labels...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovacBOzWKm3c"
      },
      "source": [
        "## KL Divergence\n",
        "This is taken as a product of the true-class probability multiplied by the log-ratio of predicted to true class probability per-sample\n",
        "$$\n",
        "\\sum_{i=1}^K p_k\\log{\\frac{p_k}{q_k}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FtmgygcI8e7",
        "outputId": "e4aed146-cebc-42de-f2aa-1ab9bfc0b861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.45814306>"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = [[0, 1], [0, 0]] \n",
        "y_pred = [[0.6, 0.4], [0.4, 0.6]]\n",
        "\n",
        "m = metrics.KLDivergence()\n",
        "m(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g589VwPXwdcD",
        "outputId": "fdb40e08-d621-46f0-fc49-5c0f44eb18e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9136630059540092"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def KL(P, Q):\n",
        "    epsilon = 1e-4\n",
        "\n",
        "    P = np.array(P) + epsilon\n",
        "    Q = np.array(Q) + epsilon\n",
        "\n",
        "    return np.sum(P*np.log(P/Q))\n",
        "\n",
        "KL(y_true, y_pred) # hmm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQCvafhi-a0W",
        "outputId": "ccc764c1-65e2-417e-8f61-9f3b27517245"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.91542078, -0.00169936])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t = np.clip(y_true, 1e-4, 1)\n",
        "p = np.clip(y_pred, 1e-4, 1)\n",
        "\n",
        "np.sum(t * np.log(t/p), axis=-1) # so then what exactly is Tensorflow's KL divergence doing?!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUB40RamweAg"
      },
      "source": [
        "# Summary\n",
        "\n",
        "This summarizes the metric name and input formats for the metris listed:\n",
        "\n",
        "| Metric | True Format | Predicted Format |   \n",
        "| --- | --- | --- |\n",
        "| Accuracy | List of classes | List of classes |  \n",
        "| Binary Accuracy | List of classes | List of class probabilities | \n",
        "| Categorical Accuracy | OHE vector of classes | Vector of class probabilites per-sample |  \n",
        "| Sparse Categorical Accuracy | List of classes (not OHE) | Vector of class probabilites per-sample |  \n",
        "| Binary Cross Entropy | List of classes | List of class probabilities |  \n",
        "| Categorical Cross Entropy | OHE vector of classes | Vector of class probabilities |  \n",
        "| Sparse Categorical Cross Entropy | List of classes | Vector of class probabilities |  \n",
        "| MAE | List of classes | List of classes |  \n",
        "| MSE | List of classes | List of classes |  \n",
        "| MAPE | List of classes | List of classes |  \n",
        "| Precision | List of binary labels | List of probabilities |  \n",
        "| Recall | List of binary labels | List of probabilities |  \n",
        "| KL Divergence | ??? | ??? |  \n",
        "\n",
        "The KL divergence in `keras` still eludes me, hopefully I should be able to make more sense of it and update it in the future.  \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XTpfu6SyHnpe",
        "S0oKfs6ezIy7",
        "rC8bkJAf1If0",
        "h1uhMpug2-Ea",
        "qz0EPdGh5SCR",
        "N8JIpUx06UJW",
        "ovacBOzWKm3c"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.15 ('basic_clean')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "def76ed885bc94f182c997508dd94bdc1bafad87e7bfd4e70b216ce388e01bfe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
