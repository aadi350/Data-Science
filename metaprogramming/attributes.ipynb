{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In [a previous post](https://aadi-blogs.web.app/blog/python-properties/), I detailed how to maintain encapsulation using Python's `property`. In this piece, I go through how/why to manage and apply validation to class attributes in an object-oriented fashion by means of a fairly plausible example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `type` is the parent class of `class`, therefore any `class` is actually a sub-type of `type`. The following are equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = int(8)\n",
    "a = 8\n",
    "type(a) # python knows to create an int without being explicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point of implementing custom attribute *types* is (in my case), for validation. The general pattern for creating a class that serves as a `type` to validate instance attributes is as follows (for a descriptor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Descriptor:\n",
    "    attribute_name: str # This stores the name of the attribute\n",
    "    def __init__(self, attribute_name):\n",
    "        self.attribute_name = attribute_name \n",
    "\n",
    "    def __set__(self, instance, value):\n",
    "        '''\n",
    "            E.g of what NOT to do, show what happens if I do\n",
    "                self.__dict__[self.attribute_name] = value\n",
    "            this modifies the class attribute for ALL Descriptor classes!\n",
    "        '''\n",
    "        if value < 0:\n",
    "            raise ValueError\n",
    "        instance.__dict__[self.attribute_name] = value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `__set__` magic method, `self` is the descriptor instance (the class `Descriptor` above), instance is the *managed* instance, and value is what we set the managed instance to. Descriptors store values of managed instances. It is in the class above that I could implement any validation on the values of the inputs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I wanted to use the above in a class (named `ManagedClass` for extreme explicitness), I create a class attribute (named `attr` again) of type `Descriptor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManagedClass:\n",
    "    attr = Descriptor('attr')\n",
    "\n",
    "    def __init__(self, attr):\n",
    "        self.attr = attr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this useful? Firstly, it maintains encapsulation, the class implementing any functionality does not also have to handle its validation of attributes **and** if the validation pattern changes, I don't have to update every single class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Repeating the Name "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's useful, but it's a bit annoying to type `attr=Description('attr')` and repeat `attr` over and over. Credit to Luciano Ramalho in the book Fluent Python for the following solution to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantity:\n",
    "    __numinstance = 0 # class attribute across ALL instances\n",
    "\n",
    "    def __init__(self, ):\n",
    "        cls = self.__class__ # cls refers to the Quantity class\n",
    "        prefix = cls.__name__\n",
    "        index = cls.__numinstance\n",
    "\n",
    "        self.attr_name = f'_{prefix}#{index}' # unique!\n",
    "        cls.__numinstance += 1 \n",
    "\n",
    "    def __get__(self, instance, owner):\n",
    "        return getattr(instance, self.attr_name) # need to implement this because name of managed attribute is NOT the same as the attr_name\n",
    "        # getattr used here bc names are different, will not trigger infinite loop\n",
    "\n",
    "    def __set__(self, instance, value):\n",
    "        setattr(instance, self.attr_name, value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, the class of the Descriptor/Quantity, etc manages a counter called `__numinstance` which generates a unique `attr_name` for every instance automatically. This way, creating a new instance does not require to pass in the name of the instance explicitly and there is no risk of index-collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManagedClass:\n",
    "    attr_name = Quantity() # this works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why this is useful\n",
    "\n",
    "This seems like a bunch of additional complexity for little to no benefit, but I'd argue for the exact opposite. Firstly (and most importantly), *users* of your code don't need to care about the internals of attribute validation, all they need to care about is the qualit of the error messages that may arise if they happen to input a value that does not match the validation.\n",
    "\n",
    "For example, let's create a `Validated` class for validating hyper-parameters for model-training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Validated abstract class\n",
    "import abc\n",
    "\n",
    "# parent class Validated\n",
    "class Validated(abc.ABC, Quantity):\n",
    "    def __set__(self, instance, value):\n",
    "        value = self.validate(instance, value)\n",
    "        super().__set__(instance, value) # THIS performans the actual storage, in this case the set method in Quantity\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def validate(self, instance, value):\n",
    "        '''Allows subclasses to implement their own validation'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also create two subclasses called `ValidateLearningRate` and `ValidatedKernelSize`. (For anyone familiar with Neural-Network parameters, you'd know that learning rate is typically between 0 and 1, and Kernel size is usually an odd number greater than 2, this varies but ConvNets use 3 or 5-sized kernels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidateLearningRate(Validated):\n",
    "    '''no numbers outsize 0 to 1'''\n",
    "    def validate(self, instance, value):\n",
    "        if value < 0 or value > 1:\n",
    "            raise ValueError('LearningRate must be > 0 and <= 1')\n",
    "        return value\n",
    "\n",
    "class ValidateKernelSize(Validated):\n",
    "    '''No non-integers'''\n",
    "    def validate(self, instance, value):\n",
    "        if not isinstance(value, int):\n",
    "            raise ValueError('Must be positive integer')\n",
    "        if value % 2 != 1:\n",
    "            raise ValueError('Value must be an odd integer')\n",
    "\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I create my class that is managed by the subclassed attributes above, which is the **only** class that my end-users interact with; let's assume that I want to build a class that allows persons to train their own neural network, and make it such that it only accepts valid hyper-parameters, and let's call this class `ConvNetTrainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetTrainer:\n",
    "    lr = ValidateLearningRate()\n",
    "    kernel_size = ValidateKernelSize()\n",
    "    # rest of class body \n",
    "    # ...\n",
    "    def __init__(self, lr, kernel_size):\n",
    "        self.lr = lr\n",
    "        self.kernel_size = kernel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try an experiment, let's test the quality of the error messages using: either one of the validated classes above vs. a default error message from a popular DL library (such as TensorFlow or FastAI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=-2) # This should not even be valid!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "LearningRate must be > 0 and <= 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m convnet_trainer \u001b[39m=\u001b[39m ConvNetTrainer(lr\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [17], line 7\u001b[0m, in \u001b[0;36mConvNetTrainer.__init__\u001b[0;34m(self, lr, kernel_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, lr, kernel_size):\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlr \u001b[39m=\u001b[39m lr\n\u001b[1;32m      8\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size \u001b[39m=\u001b[39m kernel_size\n",
      "Cell \u001b[0;32mIn [11], line 7\u001b[0m, in \u001b[0;36mValidated.__set__\u001b[0;34m(self, instance, value)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__set__\u001b[39m(\u001b[39mself\u001b[39m, instance, value):\n\u001b[0;32m----> 7\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalidate(instance, value)\n\u001b[1;32m      8\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__set__\u001b[39m(instance, value)\n",
      "Cell \u001b[0;32mIn [12], line 5\u001b[0m, in \u001b[0;36mValidateLearningRate.validate\u001b[0;34m(self, instance, value)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvalidate\u001b[39m(\u001b[39mself\u001b[39m, instance, value):\n\u001b[1;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m value \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m value \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mLearningRate must be > 0 and <= 1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m value\n",
      "\u001b[0;31mValueError\u001b[0m: LearningRate must be > 0 and <= 1"
     ]
    }
   ],
   "source": [
    "convnet_trainer = ConvNetTrainer(lr=-2, kernel_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An actually useful error message!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this hypothetical example, my end-user **only** interacts with the high-level class, and does not need to worry about the internals of *how* it goes about validation, only that it does. Additionally, if my validation method changes or becomes more robust, I don't need to update every single class using these values, rather only the parent classes (which subclasses `Validated` need be updated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ee')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88857749ff071a7b70537cd30a67825936ce24f0bdaba5a8289bced16dca050d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
